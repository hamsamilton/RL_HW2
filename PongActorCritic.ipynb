{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PongActorCritic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "suMiv5Y1ZyEl"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "import random\n",
        "import gym\n",
        "import pylab\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, Add, Conv2D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras import backend as K\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pW0nvBiZ08j"
      },
      "source": [
        "\n",
        "\n",
        "def ActorCritic(input_shape, action_space, lr):\n",
        "    X_input = Input(input_shape)\n",
        "    X = Flatten(input_shape=input_shape)(X_input)\n",
        "    X = Dense(512, activation=\"elu\", kernel_initializer='he_uniform')(X)\n",
        "    action = Dense(action_space, activation=\"softmax\", kernel_initializer='he_uniform')(X)\n",
        "    value = Dense(1, kernel_initializer='he_uniform')(X)\n",
        "\n",
        "    Actor = Model(inputs = X_input, outputs = action)\n",
        "    Actor.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=lr))\n",
        "\n",
        "    Critic = Model(inputs = X_input, outputs = value)\n",
        "    Critic.compile(loss='mse', optimizer=RMSprop(lr=lr))\n",
        "\n",
        "    return Actor, Critic"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGzYtr_4eOzG"
      },
      "source": [
        "\n",
        "\n",
        "class PongActorCritic:\n",
        "    def __init__(self, env_name):\n",
        "        # Set params\n",
        "        self.env_name = env_name       \n",
        "        self.env = gym.make(env_name)\n",
        "        self.action_size = 2 # Set to limiy actions\n",
        "        self.EPISODES, self.max_average = 10000, -21.0\n",
        "        self.lr = 0.0001\n",
        "        self.ROWS = 80\n",
        "        self.COLS = 80\n",
        "        self.REM_STEP = 4\n",
        "        self.states, self.actions, self.rewards = [], [], []\n",
        "        self.scores, self.episodes, self.average = [], [], []\n",
        "        self.state_size = (self.REM_STEP, self.ROWS, self.COLS)\n",
        "        self.image_memory = np.zeros(self.state_size)\n",
        "        self.avgrewards = []\n",
        "        # Create Actor-Critic network model\n",
        "        self.Actor, self.Critic = ActorCritic(input_shape=self.state_size, action_space = self.action_size, lr=self.lr)\n",
        "\n",
        "\n",
        "    def store(self, state, action, reward):\n",
        "        self.states.append(state)\n",
        "        action_onehot = np.zeros([self.action_size])\n",
        "        action_onehot[action] = 1\n",
        "        self.actions.append(action_onehot)\n",
        "        self.rewards.append(reward)\n",
        "\n",
        "\n",
        "    def act(self, state):\n",
        "        ''' Make a decision based on the actor model'''\n",
        "        prediction = self.Actor.predict(state)[0]\n",
        "        action = np.random.choice(self.action_size, p=prediction)\n",
        "        return action\n",
        "\n",
        "    def discount_rewards(self, reward):\n",
        "        gamma = 0.99    # discount rate\n",
        "        running_add = 0\n",
        "        discounted_r = np.zeros_like(reward)\n",
        "        for i in reversed(range(0,len(reward))):\n",
        "            if reward[i] != 0:\n",
        "                running_add = 0\n",
        "            running_add = running_add * gamma + reward[i]\n",
        "            discounted_r[i] = running_add\n",
        "        discounted_r -= np.mean(discounted_r)\n",
        "        discounted_r /= np.std(discounted_r) \n",
        "        return discounted_r\n",
        "\n",
        "                \n",
        "    def replay(self):\n",
        "        ''' Fit model and reset memory'''\n",
        "        # reshape for training\n",
        "        states = np.vstack(self.states)\n",
        "        actions = np.vstack(self.actions)\n",
        "\n",
        "        # Compute discounted rewards\n",
        "        discounted_r = self.discount_rewards(self.rewards)\n",
        "\n",
        "        # Get Critic network predictions\n",
        "        values = self.Critic.predict(states)[:, 0]\n",
        "        # Compute advantages\n",
        "        advantages = discounted_r - values\n",
        "        # training Actor and Critic networks\n",
        "        self.Actor.fit(states, actions, sample_weight=advantages, epochs=1, verbose=0)\n",
        "        self.Critic.fit(states, discounted_r, epochs=1, verbose=0)\n",
        "        # reset training memory\n",
        "        self.states, self.actions, self.rewards = [], [], []\n",
        "    \n",
        "    def getavg(self, score, episode):\n",
        "        self.scores.append(score)\n",
        "        self.episodes.append(episode)\n",
        "        self.average.append(sum(self.scores[-50:]) / len(self.scores[-50:]))\n",
        "        return self.average[-1]\n",
        "\n",
        "\n",
        "    def Preprocess(self, frame):\n",
        "        # preprocess frame to 80x80 size\n",
        "        frame_cropped = frame[35:195:2, ::2,:]\n",
        "        if frame_cropped.shape[0] != self.COLS or frame_cropped.shape[1] != self.ROWS:\n",
        "            # crop\n",
        "            frame_cropped = cv2.resize(frame, (self.COLS, self.ROWS), interpolation=cv2.INTER_CUBIC)\n",
        "        # convertto RGB\n",
        "        frame_rgb = 0.299*frame_cropped[:,:,0] + 0.587*frame_cropped[:,:,1] + 0.114*frame_cropped[:,:,2]\n",
        "        # convert everything to black and white\n",
        "        frame_rgb[frame_rgb < 100] = 0\n",
        "        frame_rgb[frame_rgb >= 100] = 255\n",
        "        # converting to RGB (OpenCV way)\n",
        "        #frame_rgb = cv2.cvtColor(frame_cropped, cv2.COLOR_RGB2GRAY)     \n",
        "\n",
        "        # Change to -1\n",
        "        new_frame = np.array(frame_rgb).astype(np.float32) / 255.0\n",
        "\n",
        "        # push our data by 1 frame, similar as deq() function work\n",
        "        self.image_memory = np.roll(self.image_memory, 1, axis = 0)\n",
        "\n",
        "        # inserting new frame to free space\n",
        "        self.image_memory[0,:,:] = new_frame\n",
        "\n",
        "        # show image frame   \n",
        "        #self.imshow(self.image_memory,0)\n",
        "        #self.imshow(self.image_memory,1)\n",
        "        #self.imshow(self.image_memory,2)\n",
        "        #self.imshow(self.image_memory,3)\n",
        "        \n",
        "        return np.expand_dims(self.image_memory, axis=0)\n",
        "\n",
        "    def reset(self):\n",
        "        frame = self.env.reset()\n",
        "        for i in range(self.REM_STEP):\n",
        "            state = self.Preprocess(frame)\n",
        "        return state\n",
        "\n",
        "    def step(self, action):\n",
        "        next_state, reward, done, info = self.env.step(action + 2)\n",
        "        next_state = self.Preprocess(next_state)\n",
        "        return next_state, reward, done, info\n",
        "    \n",
        "    def run(self):\n",
        "        for e in range(self.EPISODES):\n",
        "            state = self.reset()\n",
        "            done, score= False, 0,\n",
        "            while not done:\n",
        "                # Actor picks an action\n",
        "                action = self.act(state)\n",
        "                # Retrieve new state, reward, and whether the state is terminal\n",
        "                next_state, reward, done, _ = self.step(action)\n",
        "                self.store(state, action, reward)\n",
        "                # Update current state\n",
        "                state = next_state\n",
        "                score += reward\n",
        "                if done:\n",
        "                    average = self.getavg(score, e)\n",
        "                    # saving best models\n",
        "                    if average >= self.max_average:\n",
        "                        self.max_average = average\n",
        "                    print(\"episode: {}/{}, score: {}, average: {:.2f}\".format(e, self.EPISODES, score, average))\n",
        "\n",
        "                    self.replay()\n",
        "                    self.avgrewards.append(average)\n",
        "        # close environemnt when finish training\n",
        "        self.env.close()\n",
        "\n",
        "env_name = 'Pong-v0'\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxp9ieqgZNgu",
        "outputId": "e46a388f-3223-4e01-f423-3e5c1b24d11e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "go = PongActorCritic(env_name)\n",
        "go.run()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode: 0/10000, score: -21.0, average: -21.00\n",
            "episode: 1/10000, score: -21.0, average: -21.00\n",
            "episode: 2/10000, score: -19.0, average: -20.33\n",
            "episode: 3/10000, score: -20.0, average: -20.25\n",
            "episode: 4/10000, score: -20.0, average: -20.20\n",
            "episode: 5/10000, score: -19.0, average: -20.00\n",
            "episode: 6/10000, score: -18.0, average: -19.71\n",
            "episode: 7/10000, score: -20.0, average: -19.75\n",
            "episode: 8/10000, score: -21.0, average: -19.89\n",
            "episode: 9/10000, score: -21.0, average: -20.00\n",
            "episode: 10/10000, score: -20.0, average: -20.00\n",
            "episode: 11/10000, score: -21.0, average: -20.08\n",
            "episode: 12/10000, score: -19.0, average: -20.00\n",
            "episode: 13/10000, score: -18.0, average: -19.86\n",
            "episode: 14/10000, score: -20.0, average: -19.87\n",
            "episode: 15/10000, score: -21.0, average: -19.94\n",
            "episode: 16/10000, score: -19.0, average: -19.88\n",
            "episode: 17/10000, score: -21.0, average: -19.94\n",
            "episode: 18/10000, score: -18.0, average: -19.84\n",
            "episode: 19/10000, score: -20.0, average: -19.85\n",
            "episode: 20/10000, score: -20.0, average: -19.86\n",
            "episode: 21/10000, score: -21.0, average: -19.91\n",
            "episode: 22/10000, score: -20.0, average: -19.91\n",
            "episode: 23/10000, score: -21.0, average: -19.96\n",
            "episode: 24/10000, score: -19.0, average: -19.92\n",
            "episode: 25/10000, score: -19.0, average: -19.88\n",
            "episode: 26/10000, score: -20.0, average: -19.89\n",
            "episode: 27/10000, score: -17.0, average: -19.79\n",
            "episode: 28/10000, score: -19.0, average: -19.76\n",
            "episode: 29/10000, score: -15.0, average: -19.60\n",
            "episode: 30/10000, score: -19.0, average: -19.58\n",
            "episode: 31/10000, score: -17.0, average: -19.50\n",
            "episode: 32/10000, score: -19.0, average: -19.48\n",
            "episode: 33/10000, score: -16.0, average: -19.38\n",
            "episode: 34/10000, score: -20.0, average: -19.40\n",
            "episode: 35/10000, score: -18.0, average: -19.36\n",
            "episode: 36/10000, score: -19.0, average: -19.35\n",
            "episode: 37/10000, score: -18.0, average: -19.32\n",
            "episode: 38/10000, score: -20.0, average: -19.33\n",
            "episode: 39/10000, score: -18.0, average: -19.30\n",
            "episode: 40/10000, score: -17.0, average: -19.24\n",
            "episode: 41/10000, score: -20.0, average: -19.26\n",
            "episode: 42/10000, score: -21.0, average: -19.30\n",
            "episode: 43/10000, score: -18.0, average: -19.27\n",
            "episode: 44/10000, score: -16.0, average: -19.20\n",
            "episode: 45/10000, score: -20.0, average: -19.22\n",
            "episode: 46/10000, score: -20.0, average: -19.23\n",
            "episode: 47/10000, score: -18.0, average: -19.21\n",
            "episode: 48/10000, score: -21.0, average: -19.24\n",
            "episode: 49/10000, score: -21.0, average: -19.28\n",
            "episode: 50/10000, score: -19.0, average: -19.24\n",
            "episode: 51/10000, score: -18.0, average: -19.18\n",
            "episode: 52/10000, score: -20.0, average: -19.20\n",
            "episode: 53/10000, score: -16.0, average: -19.12\n",
            "episode: 54/10000, score: -18.0, average: -19.08\n",
            "episode: 55/10000, score: -19.0, average: -19.08\n",
            "episode: 56/10000, score: -20.0, average: -19.12\n",
            "episode: 57/10000, score: -18.0, average: -19.08\n",
            "episode: 58/10000, score: -17.0, average: -19.00\n",
            "episode: 59/10000, score: -19.0, average: -18.96\n",
            "episode: 60/10000, score: -18.0, average: -18.92\n",
            "episode: 61/10000, score: -20.0, average: -18.90\n",
            "episode: 62/10000, score: -16.0, average: -18.84\n",
            "episode: 63/10000, score: -19.0, average: -18.86\n",
            "episode: 64/10000, score: -18.0, average: -18.82\n",
            "episode: 65/10000, score: -18.0, average: -18.76\n",
            "episode: 66/10000, score: -18.0, average: -18.74\n",
            "episode: 67/10000, score: -17.0, average: -18.66\n",
            "episode: 68/10000, score: -18.0, average: -18.66\n",
            "episode: 69/10000, score: -19.0, average: -18.64\n",
            "episode: 70/10000, score: -12.0, average: -18.48\n",
            "episode: 71/10000, score: -20.0, average: -18.46\n",
            "episode: 72/10000, score: -16.0, average: -18.38\n",
            "episode: 73/10000, score: -18.0, average: -18.32\n",
            "episode: 74/10000, score: -18.0, average: -18.30\n",
            "episode: 75/10000, score: -20.0, average: -18.32\n",
            "episode: 76/10000, score: -18.0, average: -18.28\n",
            "episode: 77/10000, score: -18.0, average: -18.30\n",
            "episode: 78/10000, score: -21.0, average: -18.34\n",
            "episode: 79/10000, score: -18.0, average: -18.40\n",
            "episode: 80/10000, score: -19.0, average: -18.40\n",
            "episode: 81/10000, score: -15.0, average: -18.36\n",
            "episode: 82/10000, score: -21.0, average: -18.40\n",
            "episode: 83/10000, score: -17.0, average: -18.42\n",
            "episode: 84/10000, score: -17.0, average: -18.36\n",
            "episode: 85/10000, score: -18.0, average: -18.36\n",
            "episode: 86/10000, score: -19.0, average: -18.36\n",
            "episode: 87/10000, score: -16.0, average: -18.32\n",
            "episode: 88/10000, score: -18.0, average: -18.28\n",
            "episode: 89/10000, score: -19.0, average: -18.30\n",
            "episode: 90/10000, score: -19.0, average: -18.34\n",
            "episode: 91/10000, score: -18.0, average: -18.30\n",
            "episode: 92/10000, score: -16.0, average: -18.20\n",
            "episode: 93/10000, score: -14.0, average: -18.12\n",
            "episode: 94/10000, score: -17.0, average: -18.14\n",
            "episode: 95/10000, score: -13.0, average: -18.00\n",
            "episode: 96/10000, score: -19.0, average: -17.98\n",
            "episode: 97/10000, score: -20.0, average: -18.02\n",
            "episode: 98/10000, score: -15.0, average: -17.90\n",
            "episode: 99/10000, score: -14.0, average: -17.76\n",
            "episode: 100/10000, score: -21.0, average: -17.80\n",
            "episode: 101/10000, score: -18.0, average: -17.80\n",
            "episode: 102/10000, score: -12.0, average: -17.64\n",
            "episode: 103/10000, score: -15.0, average: -17.62\n",
            "episode: 104/10000, score: -15.0, average: -17.56\n",
            "episode: 105/10000, score: -18.0, average: -17.54\n",
            "episode: 106/10000, score: -16.0, average: -17.46\n",
            "episode: 107/10000, score: -17.0, average: -17.44\n",
            "episode: 108/10000, score: -15.0, average: -17.40\n",
            "episode: 109/10000, score: -20.0, average: -17.42\n",
            "episode: 110/10000, score: -19.0, average: -17.44\n",
            "episode: 111/10000, score: -17.0, average: -17.38\n",
            "episode: 112/10000, score: -18.0, average: -17.42\n",
            "episode: 113/10000, score: -18.0, average: -17.40\n",
            "episode: 114/10000, score: -19.0, average: -17.42\n",
            "episode: 115/10000, score: -15.0, average: -17.36\n",
            "episode: 116/10000, score: -16.0, average: -17.32\n",
            "episode: 117/10000, score: -18.0, average: -17.34\n",
            "episode: 118/10000, score: -19.0, average: -17.36\n",
            "episode: 119/10000, score: -14.0, average: -17.26\n",
            "episode: 120/10000, score: -16.0, average: -17.34\n",
            "episode: 121/10000, score: -18.0, average: -17.30\n",
            "episode: 122/10000, score: -19.0, average: -17.36\n",
            "episode: 123/10000, score: -17.0, average: -17.34\n",
            "episode: 124/10000, score: -20.0, average: -17.38\n",
            "episode: 125/10000, score: -17.0, average: -17.32\n",
            "episode: 126/10000, score: -17.0, average: -17.30\n",
            "episode: 127/10000, score: -18.0, average: -17.30\n",
            "episode: 128/10000, score: -15.0, average: -17.18\n",
            "episode: 129/10000, score: -13.0, average: -17.08\n",
            "episode: 130/10000, score: -17.0, average: -17.04\n",
            "episode: 131/10000, score: -15.0, average: -17.04\n",
            "episode: 132/10000, score: -17.0, average: -16.96\n",
            "episode: 133/10000, score: -17.0, average: -16.96\n",
            "episode: 134/10000, score: -14.0, average: -16.90\n",
            "episode: 135/10000, score: -17.0, average: -16.88\n",
            "episode: 136/10000, score: -19.0, average: -16.88\n",
            "episode: 137/10000, score: -17.0, average: -16.90\n",
            "episode: 138/10000, score: -17.0, average: -16.88\n",
            "episode: 139/10000, score: -13.0, average: -16.76\n",
            "episode: 140/10000, score: -16.0, average: -16.70\n",
            "episode: 141/10000, score: -15.0, average: -16.64\n",
            "episode: 142/10000, score: -15.0, average: -16.62\n",
            "episode: 143/10000, score: -15.0, average: -16.64\n",
            "episode: 144/10000, score: -19.0, average: -16.68\n",
            "episode: 145/10000, score: -16.0, average: -16.74\n",
            "episode: 146/10000, score: -18.0, average: -16.72\n",
            "episode: 147/10000, score: -15.0, average: -16.62\n",
            "episode: 148/10000, score: -19.0, average: -16.70\n",
            "episode: 149/10000, score: -20.0, average: -16.82\n",
            "episode: 150/10000, score: -14.0, average: -16.68\n",
            "episode: 151/10000, score: -15.0, average: -16.62\n",
            "episode: 152/10000, score: -15.0, average: -16.68\n",
            "episode: 153/10000, score: -11.0, average: -16.60\n",
            "episode: 154/10000, score: -15.0, average: -16.60\n",
            "episode: 155/10000, score: -18.0, average: -16.60\n",
            "episode: 156/10000, score: -21.0, average: -16.70\n",
            "episode: 157/10000, score: -16.0, average: -16.68\n",
            "episode: 158/10000, score: -15.0, average: -16.68\n",
            "episode: 159/10000, score: -16.0, average: -16.60\n",
            "episode: 160/10000, score: -19.0, average: -16.60\n",
            "episode: 161/10000, score: -21.0, average: -16.68\n",
            "episode: 162/10000, score: -16.0, average: -16.64\n",
            "episode: 163/10000, score: -20.0, average: -16.68\n",
            "episode: 164/10000, score: -16.0, average: -16.62\n",
            "episode: 165/10000, score: -17.0, average: -16.66\n",
            "episode: 166/10000, score: -17.0, average: -16.68\n",
            "episode: 167/10000, score: -16.0, average: -16.64\n",
            "episode: 168/10000, score: -13.0, average: -16.52\n",
            "episode: 169/10000, score: -18.0, average: -16.60\n",
            "episode: 170/10000, score: -18.0, average: -16.64\n",
            "episode: 171/10000, score: -16.0, average: -16.60\n",
            "episode: 172/10000, score: -16.0, average: -16.54\n",
            "episode: 173/10000, score: -16.0, average: -16.52\n",
            "episode: 174/10000, score: -17.0, average: -16.46\n",
            "episode: 175/10000, score: -15.0, average: -16.42\n",
            "episode: 176/10000, score: -11.0, average: -16.30\n",
            "episode: 177/10000, score: -15.0, average: -16.24\n",
            "episode: 178/10000, score: -18.0, average: -16.30\n",
            "episode: 179/10000, score: -17.0, average: -16.38\n",
            "episode: 180/10000, score: -18.0, average: -16.40\n",
            "episode: 181/10000, score: -17.0, average: -16.44\n",
            "episode: 182/10000, score: -17.0, average: -16.44\n",
            "episode: 183/10000, score: -19.0, average: -16.48\n",
            "episode: 184/10000, score: -16.0, average: -16.52\n",
            "episode: 185/10000, score: -13.0, average: -16.44\n",
            "episode: 186/10000, score: -17.0, average: -16.40\n",
            "episode: 187/10000, score: -17.0, average: -16.40\n",
            "episode: 188/10000, score: -13.0, average: -16.32\n",
            "episode: 189/10000, score: -20.0, average: -16.46\n",
            "episode: 190/10000, score: -20.0, average: -16.54\n",
            "episode: 191/10000, score: -18.0, average: -16.60\n",
            "episode: 192/10000, score: -18.0, average: -16.66\n",
            "episode: 193/10000, score: -15.0, average: -16.66\n",
            "episode: 194/10000, score: -18.0, average: -16.64\n",
            "episode: 195/10000, score: -14.0, average: -16.60\n",
            "episode: 196/10000, score: -16.0, average: -16.56\n",
            "episode: 197/10000, score: -19.0, average: -16.64\n",
            "episode: 198/10000, score: -12.0, average: -16.50\n",
            "episode: 199/10000, score: -11.0, average: -16.32\n",
            "episode: 200/10000, score: -13.0, average: -16.30\n",
            "episode: 201/10000, score: -19.0, average: -16.38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5be65393023c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPongActorCritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-29aee4b5de75>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;31m# Actor picks an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;31m# Retrieve new state, reward, and whether the state is terminal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-29aee4b5de75>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;34m''' Make a decision based on the actor model'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1577\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \"\"\"\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m       return ParallelMapDataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4043\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4045\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4046\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4047\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3369\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3370\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3371\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3373\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m     \"\"\"\n\u001b[1;32m   2938\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2939\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2940\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2904\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3362\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3363\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3364\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3365\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3297\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    446\u001b[0m   \"\"\"\n\u001b[1;32m    447\u001b[0m   logging.log(1, 'Converted call: %s\\n    args: %s\\n    kwargs: %s\\n', f, args,\n\u001b[0;32m--> 448\u001b[0;31m               kwargs)\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/utils/ag_logging.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(level, msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mecho_log_to_stdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGiQjjpWZSaR",
        "outputId": "367cb834-3efe-4a90-8b74-9d3f4c588de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(go.avgrewards)\n",
        "\n",
        "#Stopping early because of google colab limitations. It appears to be flatlining around 16.\n",
        "# The model is somewhat simple, a more complex NN could probably achieve better performance."
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa99d4a2d30>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}